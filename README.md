# üìä AV1_BIGDATA

Considerando os fundamentos te√≥ricos e pr√°ticas de laborat√≥rio ensinados na mat√©ria de Big Data lecionada por [Klayton Castro](https://github.com/klaytoncastro), exploramos v√°rias ferramentas e conceitos de Big Data, como exemplo Docker, MongoDB, Cassandra, Shell, NoSQL, entre outras... Com base na configura√ß√£o original e exemplos do reposit√≥rio [Idp-bigdata](https://github.com/klaytoncastro/idp-bigdata) esse projeto foi criado para ser avaliado na mat√©ria do professor como AV1 (Atividade Avaliativa 1).

# üêç Ferramentas e Linguagens Utilizadas
<img src="https://skillicons.dev/icons?i=py,cassandra,docker,mongodb,linux,powershell,vim" />

## ‚úÖ O que foi Desenvolvido?
- Cria√ß√£o do Ambiente do Container com Docker
- Implementa√ß√£o de Pontes de Conex√£o para interligar os sistemas com .yaml
- Subida de ambientes com Docker Compose (MongoDB, Cassandra, Jupyter).
- Manipula√ß√£o de dados:
  - CRUD completo com MongoDB e Cassandra.
  - Opera√ß√µes agregadas com MongoDB.
- Integra√ß√£o entre Jupyter e bancos NoSQL com `pymongo` e `cassandra-driver`.
- Tratamento dos Dados do INEP
- An√°lise explorat√≥ria de dados do Censo da Educa√ß√£o Superior 2022:
  - N√∫mero de institui√ß√µes por regi√£o e estado.
  - Propor√ß√£o de docentes por g√™nero.
  - Visualiza√ß√£o com gr√°ficos usando Matplotlib e Seaborn.
 
## üìÇ Estrutura do Projeto

```
BigData_AV1/
‚îÇ
‚îú‚îÄ‚îÄ docker-compose.yml             # Arquivo unificado para Jupyter, MongoDB e Cassandra
‚îú‚îÄ‚îÄ permissions.sh                 # Script para fornecer permiss√£o
‚îú‚îÄ‚îÄ wair-for-it.sh                 # Script para funcionamento do MongoDB e Cassandra
‚îú‚îÄ‚îÄ config/                        # Configura√ß√£o do Jupyter (jupyter_server_config.json)
‚îú‚îÄ‚îÄ notebooks/
‚îÇ   ‚îî‚îÄ‚îÄ AnaliseDeDados.ipynb      # Notebook da Analise de Dados do Dataset Tratado
‚îÇ   ‚îî‚îÄ‚îÄ Cassandra.ipynb           # Notebook com opera√ß√µes e an√°lise Cassandra
‚îÇ   ‚îî‚îÄ‚îÄ Mongo.ipynb               # Notebook com opera√ß√µes e an√°lise MongoDB
```

## üöÄ Como Executar o Projeto

### Pr√©-requisitos

- Docker e Docker Compose instalados
- Python 3 com bibliotecas:
  - `pymongo`
  - `cassandra-driver`
  - `pandas`
  - `matplotlib`
  - `seaborn`
  - Dataset INEP tratado

#### Como Obter e tratar o Dataset do INEP?

a) Em seu terminal, baixe e descompacte o arquivo do dataset utilizando os comandos abaixo: 

```bash
cd /opt/idp-bigdata/mongodb/datasets
wget https://download.inep.gov.br/microdados/microdados_censo_da_educacao_superior_2022.zip --no-check-certificate
unzip microdados_censo_da_educacao_superior_2022.zip
```
b) Como precisaremos apenas dos arquivos CSVs (Comma Separated Values) com as IES e Cursos por elas disponibilizados, organize a subpasta `datasets` executando os comandos abaixo para manter apenas a estrutura de pastas e dados estritamente necess√°rios. 

```bash
rm microdados_censo_da_educacao_superior_2022.zip && mv microdados_educa–ó‚ïûo_superior_2022 inep
mv inep/dados/*.CSV inep
rm -rf inep/dados && rm -rf inep/Anexos && rm -rf inep/leia-me
```

c) Precisaremos realizar a remo√ß√£o e substitui√ß√£o de caracteres indesejados para viabilizar a correta importa√ß√£o do dataset. V√° at√© a subpasta do dataset (`cd /opt/idp-bigdata/mongodb/inep`) e execute o comando abaixo:

```bash
sed 's/\"//g; s/;/,/g' MICRODADOS_ED_SUP_IES_2022.CSV > MICRODADOS_ED_SUP_IES_2022_corrigido.csv
```

d) Nos sistemas Linux, o comando `file` √© √∫til para mostrar informa√ß√µes sobre a tipagem do arquivo. A op√ß√£o `-i` solicita a apresenta√ß√£o do padr√£o de codifica√ß√£o. Ambos utilizam o padr√£o ISO 8859-1. Seguem os comandos para verificar a codifica√ß√£o aplicada aos arquivos:

```bash
file -i MICRODADOS_ED_SUP_IES_2022_corrigido.csv
file -i MICRODADOS_CADASTRO_CURSOS_2022.CSV
```
e) Nos sistemas Linux, o utilit√°rio `iconv` √© utilizado para converter a codifica√ß√£o de caracteres de determinado arquivo. O trecho `-f ISO-8859-1` indica a codifica√ß√£o original do arquivo e o trecho `-t UTF-8` indica a codifica√ß√£o desejada (convers√£o). Assim, com o comando abaixo podemos converter os arquivos do formato ISO 8859-1 para UTF-8 requerido por nosso ambiente MongoDB: 

```bash
iconv -f ISO-8859-1 -t UTF-8 MICRODADOS_ED_SUP_IES_2022_corrigido.csv > MICRODADOS_ED_SUP_IES_2022_corrigido_UTF8.csv
```
#### Normaliza√ß√£o de Texto

```bash
sed -i 'y/√°√†√£√¢√§√©√®√™√´√≠√¨√Æ√Ø√≥√≤√µ√¥√∂√∫√π√ª√º√ß√±√Å√Ä√É√Ç√Ñ√â√à√ä√ã√ç√å√é√è√ì√í√ï√î√ñ√ö√ô√õ√ú√á√ë/aaaaaeeeeiiiiooooouuuucnAAAAAEEEEIIIIOOOOOUUUUCN/' MICRODADOS_ED_SUP_IES_2022_corrigido_UTF8.csv
```
#### Importa√ß√£o para o MongoDB

```bash
docker exec -it mongo_service mongoimport --db inep --collection ies --type csv --file /datasets/inep/MICRODADOS_ED_SUP_IES_2022_corrigido_UTF8.csv --headerline --ignoreBlanks --username root --password mongo --authenticationDatabase admin
```
a) Agora vamos repetir todo o processo de prepara√ß√£o, limpeza e importa√ß√£o para o arquivo que ir√° alimentar a collection `cursos`: 

```bash
sed 's/\"//g; s/;/,/g' MICRODADOS_CADASTRO_CURSOS_2022.CSV > MICRODADOS_CADASTRO_CURSOS_2022_corrigido.CSV

iconv -f ISO-8859-1 -t UTF-8 MICRODADOS_CADASTRO_CURSOS_2022_corrigido.CSV > MICRODADOS_CADASTRO_CURSOS_2022_corrigido_UTF8.CSV

sed -i 'y/√°√†√£√¢√§√©√®√™√´√≠√¨√Æ√Ø√≥√≤√µ√¥√∂√∫√π√ª√º√ß√±√Å√Ä√É√Ç√Ñ√â√à√ä√ã√ç√å√é√è√ì√í√ï√î√ñ√ö√ô√õ√ú√á√ë/aaaaaeeeeiiiiooooouuuucnAAAAAEEEEIIIIOOOOOUUUUCN/' MICRODADOS_CADASTRO_CURSOS_2022_corrigido_UTF8.CSV

docker exec -it mongo_service mongoimport --db inep --collection cursos --type csv --file /datasets/inep/MICRODADOS_CADASTRO_CURSOS_2022_corrigido_UTF8.CSV --headerline --ignoreBlanks --username root --password mongo --authenticationDatabase admin
```

---

- ## üìÅ Refer√™ncias Base

- Jupyter: https://github.com/klaytoncastro/idp-bigdata/tree/main/jupyter  
- MongoDB: https://github.com/klaytoncastro/idp-bigdata/tree/main/mongodb  
- Cassandra: https://github.com/klaytoncastro/idp-bigdata/tree/main/cassandra  
